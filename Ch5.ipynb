{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9026ce-be49-4c23-8832-90493452af53",
   "metadata": {},
   "source": [
    "# 딥러닝 기초\n",
    "\n",
    "## CH5 과제\n",
    "\n",
    "## 2020100381 안정빈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457a2c7-d5cf-499a-a063-6eed6491854c",
   "metadata": {},
   "source": [
    "# CH5. 오차역전파법\n",
    "+ 수치 미분을 사용한 가중치 매개변수의 기울기를 구하는 방법은 계산 시간이 오래 걸리는 단점이 존재\n",
    "+ 오차역전파법을 이용하면 가중치 매개변수의 기울기를 효율적으로 계산 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793531c3-2b84-4cf4-bbb2-a0c3a67bb98d",
   "metadata": {},
   "source": [
    "## 5-1. 계산 그래프\n",
    "\n",
    "+ 계산 과정을 표현한 그래프로, 복수의 노드와 에지(노드 사이의 직선)으로 표현한다.\n",
    "+ 노드는 원(O)으로 표현하고, 원 안에 연산 내용을 적는다.\n",
    "+ 계산 결과를 화살표 위에 적어, 각 노드의 계산 결과가 왼쪽에서 오른쪽으로 전해지게 한다.\n",
    "+ 계산을 왼쪽에서 오른쪽으로 진행하는 단계를 순전파라고 한다.\n",
    "+ 계산 그래프는, 국소적 계산을 전파한다. 즉, 각 노드는 자신과 관련한 계산 외에는 다른 계산을 신경쓰지 않는다.\n",
    "+ 이러한 국소적 계산을 통해 결과를 전달함으로써, 전체를 구성하는 복잡한 계산을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7c52b-0e5b-4e3e-8d78-9d4d1e3c1948",
   "metadata": {},
   "source": [
    "### 5-1-3. 계산 그래프의 장점\n",
    "1. 국소적 계산을 통해, 복잡한 문제를 단순화\n",
    "2. 중간 계산 결과를 모두 보관 가능\n",
    "3. 역전파를 통해 '미분'을 효율적으로 계산할 수 있다.\n",
    "\n",
    "=> 순전파와 역전파를 활용해 각 변수의 미분을 효율적으로 구할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fba79-e82f-4725-a687-7341d4303058",
   "metadata": {},
   "source": [
    "## 5-2. 연쇄법칙\n",
    "+ 역전파는 '국소적인 미분'을 오른쪽에서 왼쪽으로 전달. 이러한 '국소적 미분'을 전달하는 원리는 연쇄법칙을 따름\n",
    "+ 연쇄법칙 원리: 합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb041fb-6acf-4dc1-ac8c-184c477a4f6a",
   "metadata": {},
   "source": [
    "## 5-3. 역전파\n",
    "+ 덧셈 노드의 역전파: 덧셈 노드는 입력값을 단순히 더하는 역할만 하기 때문에 역전파에서 입력 신호는 절대로 바뀌지 않는다.\n",
    "  즉, 덧셈 노드는 \"입력 신호가 그대로 다음 노드로 전파된다.\n",
    "+ 곱셈 노드의 역전파: 상류의 값에, 순전파 때의 입력 신호들을 서로 바꾼 값을 곱해서 하류로 보낸다.\n",
    "+ 덧셈의 역전파에서는 순방향 입력 신호의 값이 필요하지 않지만, 곱셈의 역전파는 순방향 입력 신호의 값이 필요\n",
    "\n",
    "=> 곱셈 노드 구현시, 순전파의 입력 신호를 변수에 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4eab6-debd-48bd-8941-830c3aa521fa",
   "metadata": {},
   "source": [
    "## 5-4. 단순한 계층 구현하기 \n",
    "사과 쇼핑의 예를 파이썬으로 구현 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d21825-f661-426a-870f-1596b8556f71",
   "metadata": {},
   "source": [
    "### 5-4-1. 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d41cc5-8139-43bf-beac-ddd2c5f54268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer: # 계산 그래프의 곱셈 노드 \n",
    "    def __init__(self): # x와 y의 초기화 역할\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        out= x*y\n",
    "\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=dout*self.y # x와 y를 바꾼다.\n",
    "        dy=dout*self.x \n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23afc6f3-e97f-4572-a16f-209d00569cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple= 100\n",
    "apple_num=2\n",
    "tax= 1.1 \n",
    "\n",
    "# 계층 구현 \n",
    "mul_apple_layer=MulLayer()\n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price=mul_apple_layer.forward(apple, apple_num)\n",
    "price=mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0534e948-3d3f-4630-acb2-cf146c80ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# 역전파 \n",
    "dprice=1\n",
    "dapple_price, dtax=mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num=mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3d71c-beb6-402a-991c-e1bc7d8f3fda",
   "metadata": {},
   "source": [
    "### 5-4-2. 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37f60282-28bf-4a1a-98e7-00f76f7349f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x,y):\n",
    "        out=x+y\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx= dout * 1\n",
    "        dy= dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7225048-fa0f-4eeb-8a66-76135939d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 165.0 3.3000000000000003 650\n"
     ]
    }
   ],
   "source": [
    "apple=100\n",
    "apple_num=2\n",
    "orange=150\n",
    "orange_num=3\n",
    "tax=1.1\n",
    "\n",
    "# 계층 \n",
    "mul_apple_layer=MulLayer()\n",
    "mul_orange_layer=MulLayer()\n",
    "add_apple_orange_layer=AddLayer()\n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price=mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price=mul_orange_layer.forward(orange, orange_num)\n",
    "all_price=add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price=mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 역전파 \n",
    "dprice=1\n",
    "dall_price, dtax=mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price=add_apple_orange_layer.backward(dall_price)\n",
    "dorange, dorange_num=mul_orange_layer.backward(dorange_price)\n",
    "dapple, dapple_num= mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple_num, dapple, dorange_num, dorange, dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431582a7-bebb-4046-a5c2-509f1b88a1a4",
   "metadata": {},
   "source": [
    "## 5-5. 활성화 함수 계층 구현하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3771c-6129-4aa1-b74c-b7c16a23dd3d",
   "metadata": {},
   "source": [
    "### 5-5-1. RelU 계층\n",
    "+ ReLU: 순전파 때 입력인 x가 0보다 크면, 역전파는 상류의 값을 그대로 하류로 보냄\n",
    "  순전파 때 x가 0이하면, 역전파 때는 0을 보냄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ce8c66-d2a7-45d7-896e-f8f76d496dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelU:\n",
    "    def __init__(self):\n",
    "        self.mask= None \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x<=0)\n",
    "        out=x.copy()\n",
    "        out[self.mask]=0\n",
    "\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]=0\n",
    "        dx=dout\n",
    "\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c4264-2b20-4f2e-b535-b46f0469e4b0",
   "metadata": {},
   "source": [
    "mask: True/False로 구성된 넘파이 배열로, ReLU의 역전파를 위한 기억 장치이다.\n",
    "\n",
    "순전파의 입력인 x의 원소 값이 0이하인 인덱스는 True, 그 외는 False로 유지한다.\n",
    "\n",
    "역잔파 경우, 순전파 때 만들어둔 mask를 써서 mask의 원소가 True인 곳에는 상류에서 전파된 dout을 0으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d705b75-ab68-4b6f-ae24-ff9f9fcd101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([[1.0, -0.5],[-2.0,3.0]])\n",
    "print(x)\n",
    "mask=(x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65cffe-749b-4c7f-9a3d-9118b6c1dc62",
   "metadata": {},
   "source": [
    "### 5-5-2. Sigmoid 계층\n",
    "+ sigmoid 계층의 역전파는 순전파의 출력(y)만으로 계산이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9521e9d-1b82-41bd-95b7-3779b08f169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out=None\n",
    "\n",
    "    def forwar(self, x):\n",
    "        out= 1 / (1+np.exp(-x))\n",
    "        self.out=out\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=dout*(1.0-self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8448f1-68be-460d-b130-52bf77f02fa4",
   "metadata": {},
   "source": [
    "## 5-6. Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce83d2-753f-485f-aa3a-9cbf2b80f8d7",
   "metadata": {},
   "source": [
    "### 5-6-1. Affine 계층\n",
    "+ 입력에 가중치를 더하고, 편향을 더하는 연산\n",
    "+ 행렬 곱의 역전파는 행렬의 대응하는 차원의 원소 수가 일치하도록 곱을 취하여 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ee1de3f-ba47-4e2a-91ae-bd8de05c0024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 아핀 계층 구현\n",
    "X=np.random.rand(2)\n",
    "W=np.random.rand(2,3)\n",
    "B=np.random.rand(3)\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "y=np.dot(X,W)+B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad1c5c-4592-4735-ab44-f7ae66fff454",
   "metadata": {},
   "source": [
    "### 5-6-2. 배치용 Affine 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31b4c4cb-89ea-4a2c-975c-c6db02dd7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "X_dot_W=np.array([[0,0,0],[10,10,10]])\n",
    "B=np.array([1,2,3])\n",
    "\n",
    "print(X_dot_W)\n",
    "print(X_dot_W+B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb1fbb-1804-4082-8bab-900531ce5043",
   "metadata": {},
   "source": [
    "순전파의 편향 덧셈은 각각의 데이터(1 번째 데이터, 2번째 데이터)에 더해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d7cdfd0-283b-42af-8388-f15735010fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# 역전파\n",
    "dY=np.array([[1,2,3],[4,5,6]])\n",
    "print(dY)\n",
    "dB=np.sum(dY, axis=0) # 편향의 역전파는 그 두 데이터에 대한 미분을 데이터마다 더해서 구함 => 0번째 축에서의 총합과 동일\n",
    "print(dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f941e01-c91f-4c4b-bbe5-bccf6afb9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W,b):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dW=None\n",
    "        self.db=None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x=x\n",
    "        out=np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out \n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx=np.dot(dout, self.W.T)\n",
    "        self.dW=np.dot(self.x.T, dout)\n",
    "        self.db=np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07ca52-a7aa-46a7-9f30-019febfa8664",
   "metadata": {},
   "source": [
    "### 5-6-3. Softmax-with-Loss 계층\n",
    "+ Affine 계층과 RelU 계층을 통과하며 변환되고, 마지막 softmax 계층에 의해서 입력이 정규화된다.\n",
    "+ Softmax 계층은 입력 값을 정규화(출력의 합이 1이 되도록 변형)한다.\n",
    "+ 오차 계층은 softmax의 출력(y)와 정답 레이블(t)를 받고, 이 데이터들로부터 손실 L을 출력한다.\n",
    "+ softmax 계층의 역전파는 (y1-t1 , y2-t2, y3-t3)과 같이 깔금하게 나온다. -> 즉 softmax 계층의 출력과 정답 레이블의 오차를 있는 그대로 드러내,\n",
    "   softmax 계층의 앞 계층들은 오차로부터 큰 깨달음을 얻게 된다.\n",
    "+ 소프트맥스 함수와 크로스 엔트로피 오차를 함께 이용시, 미분 값을 깔끔하게 얻을 수 있고, 효율적인 역전파가 가능해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52991550-0a78-4122-81b5-a57ca63e8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y=None\n",
    "        self.t=None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y=softmax(x)\n",
    "        self.loss=cross_entropy_error(self.y , self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size=self.t.shape[0]\n",
    "        dx=(self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b33b1-d150-43a8-8eb0-2288edea2aa9",
   "metadata": {},
   "source": [
    "## 5-7. 오차역전파법 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "023fda76-3e81-4978-ba11-bee1646a008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차역전파법을 적용한 신경망 구현\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), 'common'))\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1']=np.zeros(hidden_size)\n",
    "        self.params['W2']=weight_init_std * np.random.randn(hidden_size,output_size)\n",
    "        self.params['b2']=np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers=OrderedDict() # 순서가 있는 딕셔너리 => 추가한 순서를 기억\n",
    "        self.layers['Affine1']=Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1']=Relu()\n",
    "        self.layers['Affine2']=Affine(self.params['W2'],self.params['b2'])\n",
    "\n",
    "        self.lastLayer=SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x=layer.forward(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    # x: 입력 데이터, t:정답 레이블 \n",
    "    def loss(self, x, t):\n",
    "        y=self.predict(x)\n",
    "\n",
    "        return self.lastLayer.forward(y,t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y=self.predict(x)\n",
    "        y=np.argmax(y, axis=1)\n",
    "        if t.ndim != 1: t=np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy=np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W:self.loss(x,t)\n",
    "\n",
    "        grads={}\n",
    "        grads['W1']=numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1']=numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2']=numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2']=numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads \n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # 순전파 \n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout=1\n",
    "        dout=self.lastLayer.backward(dout)\n",
    "\n",
    "        layers=list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)\n",
    "\n",
    "        grads={}\n",
    "        grads['W1']=self.layers['Affine1'].dW\n",
    "        grads['b1']=self.layers['Affine1'].db\n",
    "        grads['W2']=self.layers['Affine2'].dW\n",
    "        grads['b2']=self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e0c15-8658-408e-ba7b-bf27e719d122",
   "metadata": {},
   "source": [
    "### 5-7-3. 오차역전파법으로 구한 기울기 검증\n",
    "+ 기울기 구하는 방법은 1. 수치 미분 이용 2. 오차 역전파법\n",
    "+ 수치 미분은 느리지만, 구현이 쉬워서 버그를 찾기가 쉽다.\n",
    "+ 반대로 오차역전파법은 속도가 빠르나, 구현이 복잡해서 실수가 있을 수 있다.\n",
    "+ => 수치 미분의 결과와 오차역전파법의 결과를 비교하여, 두 방식으로 구한 기울기가 일치함을 확인하는 작업을 기울기 확인이라 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d07b273-751d-4e63-9054-124343208731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:4.520294807086996e-10\n",
      "b1:2.639433318324825e-09\n",
      "W2:5.70191685571409e-09\n",
      "b2:1.4037041328324172e-07\n"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 데이터 읽기 \n",
    "(x_train, t_train),(x_test,t_test)=load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network=TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "x_batch=x_train[:3]\n",
    "t_batch=t_train[:3]\n",
    "\n",
    "grad_numerical=network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop=network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 낸다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff=np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \":\"+ str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa50f43-e571-4d37-89de-fdf4b8ee87cf",
   "metadata": {},
   "source": [
    "### 5-7-4. 오차역전파법을 사용한 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "703b9dbf-f8bb-422f-9887-585bbf761080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0795 0.0818\n",
      "0.90495 0.909\n",
      "0.9251333333333334 0.9276\n",
      "0.9385666666666667 0.9396\n",
      "0.94515 0.946\n",
      "0.9512666666666667 0.9508\n",
      "0.95835 0.9549\n",
      "0.9607833333333333 0.958\n",
      "0.9659833333333333 0.9616\n",
      "0.9693833333333334 0.9636\n",
      "0.9705166666666667 0.9658\n",
      "0.9729166666666667 0.9657\n",
      "0.9743833333333334 0.9684\n",
      "0.976 0.9694\n",
      "0.9775833333333334 0.9707\n",
      "0.9790166666666666 0.9714\n",
      "0.9801 0.9715\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽기 \n",
    "(x_train, t_train),(x_test,t_test)=load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network=TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
